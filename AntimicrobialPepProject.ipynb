{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> \"Protein Feature Calculation and Machine Learning Classification of Peptides\" </h1>\n",
        "<h2> Protein Feature Calculation and Machine Learning </h2>\n",
        "\n",
        "This code installs the required packages and libraries, downloads peptide datasets, removes redundant sequences, calculates different protein features, and trains a machine learning model to classify the peptides as either positive or negative."
      ],
      "metadata": {
        "id": "Huu7Gy6sDWek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "To install the necessary packages and libraries, run the following commands:"
      ],
      "metadata": {
        "id": "3-CjgyQ3Le4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pfeature Installation**\n",
        "This script also downloads and installs the Pfeature library, which provides various features for protein sequences. To install Pfeature, simply run the script provided. This will download the Pfeature ZIP file, unzip it, navigate to the Pfeature directory, and run the setup script. After running the script, Pfeature will be installed on your system and can be imported and used in your Python scripts. "
      ],
      "metadata": {
        "id": "dDeWUddeSFNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "# Download and install Pfeature\n",
        "!wget https://github.com/raghavagps/Pfeature/raw/master/PyLib/Pfeature.zip\n",
        "!unzip Pfeature.zip\n",
        "%cd Pfeature\n",
        "!python setup.py install\n",
        "\n",
        "# Install CD-HIT\n",
        "!conda install -c bioconda cd-hit -y"
      ],
      "metadata": {
        "id": "xmfjC4ciOYyM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usage**\n",
        "To download the peptide datasets and remove redundant sequences, run the following commands:"
      ],
      "metadata": {
        "id": "tMLfLbQiMEi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download peptide datasets\n",
        "!wget https://raw.githubusercontent.com/AshifInn/AntimicPeptides/main/train_po.fasta\n",
        "!wget https://raw.githubusercontent.com/AshifInn/AntimicPeptides/main/train_ne.fasta\n",
        "!cat train_ne.fasta \n",
        "\n",
        "# Remove redundant sequences using CD-HIT\n",
        "!cd-hit -i train_po.fasta -o train_po_cdhit.txt -c 0.99\n",
        "!cd-hit -i train_ne.fasta -o train_ne_cdhit.txt -c 0.99\n",
        "!ls -l\n",
        "!grep \">\" train_po_cdhit.txt | wc -l\n",
        "!grep \">\" train_po.fasta | wc -l\n",
        "!grep \">\" train_ne.fasta | wc -l\n",
        "!grep \">\" train_ne_cdhit.txt | wc -l"
      ],
      "metadata": {
        "id": "lSaaY-VROcpx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate protein features, use the following functions:"
      ],
      "metadata": {
        "id": "yYugOsvtMPpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for calculating different features\n",
        "import pandas as pd\n",
        "\n",
        "# Amino acid composition (AAC)\n",
        "from Pfeature.pfeature import aac_wp\n",
        "\n",
        "def calc_aac(input_file):\n",
        "  # Create output file name\n",
        "  output_file = input_file.rstrip('txt') + 'aac.csv'\n",
        "  # Calculate AAC feature and save to output file\n",
        "  aac_wp(input_file, output_file)\n",
        "  # Load output file as pandas dataframe\n",
        "  df = pd.read_csv(output_file)\n",
        "  return df\n",
        "\n",
        "# Dipeptide composition (DPC)\n",
        "from Pfeature.pfeature import dpc_wp\n",
        "\n",
        "def calc_dpc(input_file):\n",
        "  # Create output file name\n",
        "  output_file = input_file.rstrip('txt') + 'dpc.csv'\n",
        "  # Calculate DPC feature and save to output file\n",
        "  dpc_wp(input_file, output_file, 1)\n",
        "  # Load output file as pandas dataframe\n",
        "  df = pd.read_csv(output_file)\n",
        "  return df\n",
        "\n",
        "# Calculate feature for both positive and negative classes, combine the two classes, and merge with class labels\n",
        "pos_file = 'train_po_cdhit.txt'\n",
        "neg_file = 'train_ne_cdhit.txt'\n"
      ],
      "metadata": {
        "id": "528Gra7VOjy1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Calculation and Data Preprocessing**\n",
        "This script contains a function calc_features that calculates features for positive and negative classes and combines them with class labels to create a Pandas dataframe. The function takes in three arguments:\n",
        "\n",
        "1. pos_file: file containing the positive class data\n",
        "2. neg_file: file containing the negative class data\n",
        "3. feature_calc_func: function used to calculate the features for each class\n",
        "\n",
        "The function returns a Pandas dataframe with the combined features and class labels. The script also demonstrates how to use calc_features to calculate the AAC and DPC features for a given dataset. Finally, it performs some data preprocessing on the AAC feature dataframe and assigns the features to X and the labels to y. "
      ],
      "metadata": {
        "id": "SS0ROyLxL5EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_features(pos_file, neg_file, feature_calc_func):\n",
        "  # Calculate feature for positive and negative classes\n",
        "  pos_feature = feature_calc_func(pos_file)\n",
        "  neg_feature = feature_calc_func(neg_file)\n",
        "  # Create class labels\n",
        "  pos_class = pd.Series(['positive' for i in range(len(pos_feature))])\n",
        "  neg_class = pd.Series(['negative' for i in range(len(neg_feature))])\n",
        "  # Combine positive and negative classes\n",
        "  po_ne_class = pd.concat([pos_class, neg_class], axis=0)\n",
        "  po_ne_class.name = 'class'\n",
        "  po_ne_feature = pd.concat([pos_feature, neg_feature], axis=0)\n",
        "  # Combine feature and class\n",
        "  df = pd.concat([po_ne_feature, po_ne_class], axis=1)\n",
        "  return df\n",
        "\n",
        "# Calculate AAC feature\n",
        "aac_feature = calc_features(pos_file, neg_file, calc_aac)\n",
        "\n",
        "\n",
        "# Calculate DPC feature\n",
        "dpc_feature = calc_features(pos_file, neg_file, calc_dpc)\n",
        "\n",
        "# Data pre-processing\n",
        "aac_feature\n",
        "# Assign X and y\n",
        "X = aac_feature.iloc[:, :-1]\n",
        "y = aac_feature.iloc[:, -1]"
      ],
      "metadata": {
        "id": "AUDaOAt0PAPr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning**\n",
        "To train a machine learning model, import the desired model from the sklearn library and call the fit function on the training data. In this example, we use a logistic regression model from the sklearn.linear_model module."
      ],
      "metadata": {
        "id": "kNYrGLj7NhF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Standardize data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train_std = sc.fit_transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=1)\n",
        "classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(X_test_std)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KzKG61IDIWEn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To evaluate the model's performance,** import the desired evaluation metric(s) from the sklearn.metrics module and apply them to the true test labels and the predicted labels. In this example, we use the confusion_matrix and accuracy_score functions."
      ],
      "metadata": {
        "id": "fBCNpy08OB57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(confusion_matrix)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "iJNoYk_FPSfr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyfrT1C2N2IM",
        "outputId": "5552903f-4c0f-4ecb-e3a1-94455fd4c9d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[301, 123],\n",
              "       [129, 275]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "gq7xcftWfaZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d0b582-1fcd-419b-ea16-3037e910ce7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6956521739130435"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}